{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitmlvenvvirtualenv7d88894919b14083a2990028bc2685ff",
   "display_name": "Python 3.6.8 64-bit ('ml_venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\n -> X.shape = (144, 7), y.shape = (144,), n_classes = 3\n\nNeural network model:\n input_dim = 7\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 100.00%, acc_valid = 91.67% (n_train = 108, n_valid = 36)\n Fold 2/4: acc_train = 97.22%, acc_valid = 100.00% (n_train = 108, n_valid = 36)\n Fold 3/4: acc_train = 98.15%, acc_valid = 97.22% (n_train = 108, n_valid = 36)\n Fold 4/4: acc_train = 100.00%, acc_valid = 88.89% (n_train = 108, n_valid = 36)\n***************************** GENERIC MODEL TRAINING RESULTS ********************\n  \n    -> acc_train_avg = 98.84%, acc_valid_avg = 94.44% \n\n\nsplits made =  7\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 85.19%, acc_valid = 83.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 85.19%, acc_valid = 86.11% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 83.33%, acc_valid = 91.67% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 88.89%, acc_valid = 72.22% (n_train = 108, n_valid 36)\n0  : \n  -> acc_train_avg = 85.65%, acc_valid_avg = 83.33%\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 87.96%, acc_valid = 83.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 87.04%, acc_valid = 88.89% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 84.26%, acc_valid = 94.44% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 89.81%, acc_valid = 77.78% (n_train = 108, n_valid 36)\n1  : \n  -> acc_train_avg = 87.27%, acc_valid_avg = 86.11%\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 57.41%, acc_valid = 58.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 56.48%, acc_valid = 44.44% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 58.33%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 57.41%, acc_valid = 47.22% (n_train = 108, n_valid 36)\n2  : \n  -> acc_train_avg = 57.41%, acc_valid_avg = 51.39%\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 83.33%, acc_valid = 72.22% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 78.70%, acc_valid = 88.89% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 79.63%, acc_valid = 88.89% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 80.56%, acc_valid = 69.44% (n_train = 108, n_valid 36)\n3  : \n  -> acc_train_avg = 80.56%, acc_valid_avg = 79.86%\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 81.48%, acc_valid = 83.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 82.41%, acc_valid = 83.33% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 82.41%, acc_valid = 83.33% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 87.96%, acc_valid = 66.67% (n_train = 108, n_valid 36)\n4  : \n  -> acc_train_avg = 83.56%, acc_valid_avg = 79.17%\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 56.48%, acc_valid = 63.89% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 53.70%, acc_valid = 52.78% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 58.33%, acc_valid = 61.11% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 61.11%, acc_valid = 50.00% (n_train = 108, n_valid 36)\n5  : \n  -> acc_train_avg = 57.41%, acc_valid_avg = 56.94%\nNeural network model:\n input_dim = 1\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 68.52%, acc_valid = 63.89% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 66.67%, acc_valid = 69.44% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 66.67%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 64.81%, acc_valid = 77.78% (n_train = 108, n_valid 36)\n6  : \n  -> acc_train_avg = 66.67%, acc_valid_avg = 66.67%\nhitting new\n[1.8146526861901364]   **  [-1.88872864]\n[1.8174394707377135]   **  [1.78561708]\n[1.7029599244302125]   **  [-1.34439308]\n[1.0030990185410584]   **  [0.88104633]\n[1.835946784098858]   **  [-0.71997565]\n[2.0900830338362266]   **  [1.60394238]\n[-1.7790681614731618]   **  [1.65057056]\n[-2.1285141963526533]   **  [1.95925839]\n[-1.9325429604699484]   **  [-1.90684638]\n[-1.597020973256277]   **  [1.90836695]\n[ 1.81465269 -1.88872864]   **  [1.95239993]\n[1.81743947 1.78561708]   **  [-0.56105011]\n[ 1.70295992 -1.34439308]   **  [1.5626738]\n[1.00309902 0.88104633]   **  [1.23366575]\n[ 1.83594678 -0.71997565]   **  [1.93830869]\n[2.09008303 1.60394238]   **  [0.09742937]\n[-1.77906816  1.65057056]   **  [-1.29366549]\n[-2.1285142   1.95925839]   **  [-0.12475722]\n[-1.93254296 -1.90684638]   **  [1.4389921]\n[-1.59702097  1.90836695]   **  [-1.63920032]\n[ 1.81465269 -1.88872864  1.95239993]   **  [0.34201399]\n[ 1.81743947  1.78561708 -0.56105011]   **  [-1.55249437]\n[ 1.70295992 -1.34439308  1.5626738 ]   **  [2.30849625]\n[1.00309902 0.88104633 1.23366575]   **  [2.48710886]\n[ 1.83594678 -0.71997565  1.93830869]   **  [-2.13648312]\n[2.09008303 1.60394238 0.09742937]   **  [0.95631881]\n[-1.77906816  1.65057056 -1.29366549]   **  [2.42773658]\n[-2.1285142   1.95925839 -0.12475722]   **  [1.61459196]\n[-1.93254296 -1.90684638  1.4389921 ]   **  [1.85852403]\n[-1.59702097  1.90836695 -1.63920032]   **  [-2.54227799]\n[ 1.81465269 -1.88872864  1.95239993  0.34201399]   **  [1.95533217]\n[ 1.81743947  1.78561708 -0.56105011 -1.55249437]   **  [1.99407676]\n[ 1.70295992 -1.34439308  1.5626738   2.30849625]   **  [-0.86011633]\n[1.00309902 0.88104633 1.23366575 2.48710886]   **  [-1.35666026]\n[ 1.83594678 -0.71997565  1.93830869 -2.13648312]   **  [1.7013274]\n[2.09008303 1.60394238 0.09742937 0.95631881]   **  [-1.56737448]\n[-1.77906816  1.65057056 -1.29366549  2.42773658]   **  [-1.08127185]\n[-2.1285142   1.95925839 -0.12475722  1.61459196]   **  [1.67264946]\n[-1.93254296 -1.90684638  1.4389921   1.85852403]   **  [1.67635183]\n[-1.59702097  1.90836695 -1.63920032 -2.54227799]   **  [-2.19220355]\n[ 1.81465269 -1.88872864  1.95239993  0.34201399  1.95533217]   **  [-0.85065373]\n[ 1.81743947  1.78561708 -0.56105011 -1.55249437  1.99407676]   **  [-1.02395852]\n[ 1.70295992 -1.34439308  1.5626738   2.30849625 -0.86011633]   **  [1.99763252]\n[ 1.00309902  0.88104633  1.23366575  2.48710886 -1.35666026]   **  [-0.91392581]\n[ 1.83594678 -0.71997565  1.93830869 -2.13648312  1.7013274 ]   **  [-1.18303994]\n[ 2.09008303  1.60394238  0.09742937  0.95631881 -1.56737448]   **  [1.69717456]\n[-1.77906816  1.65057056 -1.29366549  2.42773658 -1.08127185]   **  [1.25948626]\n[-2.1285142   1.95925839 -0.12475722  1.61459196  1.67264946]   **  [-0.80595458]\n[-1.93254296 -1.90684638  1.4389921   1.85852403  1.67635183]   **  [1.22327214]\n[-1.59702097  1.90836695 -1.63920032 -2.54227799 -2.19220355]   **  [-0.93320307]\n[ 1.81465269 -1.88872864  1.95239993  0.34201399  1.95533217 -0.85065373]   **  [1.31767916]\n[ 1.81743947  1.78561708 -0.56105011 -1.55249437  1.99407676 -1.02395852]   **  [1.33814346]\n[ 1.70295992 -1.34439308  1.5626738   2.30849625 -0.86011633  1.99763252]   **  [2.04268175]\n[ 1.00309902  0.88104633  1.23366575  2.48710886 -1.35666026 -0.91392581]   **  [2.02258213]\n[ 1.83594678 -0.71997565  1.93830869 -2.13648312  1.7013274  -1.18303994]   **  [1.48188753]\n[ 2.09008303  1.60394238  0.09742937  0.95631881 -1.56737448  1.69717456]   **  [0.15780355]\n[-1.77906816  1.65057056 -1.29366549  2.42773658 -1.08127185  1.25948626]   **  [1.52432456]\n[-2.1285142   1.95925839 -0.12475722  1.61459196  1.67264946 -0.80595458]   **  [-2.3638123]\n[-1.93254296 -1.90684638  1.4389921   1.85852403  1.67635183  1.22327214]   **  [-1.06351161]\n[-1.59702097  1.90836695 -1.63920032 -2.54227799 -2.19220355 -0.93320307]   **  [-2.15701531]\n1\n2\n[[array([ 1.81465269, -1.88872864,  1.95239993,  0.34201399,  1.95533217,\n       -0.85065373,  1.31767916]), array([ 1.81743947,  1.78561708, -0.56105011, -1.55249437,  1.99407676,\n       -1.02395852,  1.33814346]), array([ 1.70295992, -1.34439308,  1.5626738 ,  2.30849625, -0.86011633,\n        1.99763252,  2.04268175]), array([ 1.00309902,  0.88104633,  1.23366575,  2.48710886, -1.35666026,\n       -0.91392581,  2.02258213]), array([ 1.83594678, -0.71997565,  1.93830869, -2.13648312,  1.7013274 ,\n       -1.18303994,  1.48188753]), array([ 2.09008303,  1.60394238,  0.09742937,  0.95631881, -1.56737448,\n        1.69717456,  0.15780355]), array([-1.77906816,  1.65057056, -1.29366549,  2.42773658, -1.08127185,\n        1.25948626,  1.52432456]), array([-2.1285142 ,  1.95925839, -0.12475722,  1.61459196,  1.67264946,\n       -0.80595458, -2.3638123 ]), array([-1.93254296, -1.90684638,  1.4389921 ,  1.85852403,  1.67635183,\n        1.22327214, -1.06351161]), array([-1.59702097,  1.90836695, -1.63920032, -2.54227799, -2.19220355,\n       -0.93320307, -2.15701531])], array([[ 0.8529648 ,  0.58828095,  0.71331995,  0.71057454,  0.64400159,\n         0.50785618,  0.28724581, -0.58872777, -0.18242864, -0.37220648],\n       [ 0.11026065,  0.81088462, -0.19287093, -0.24530988,  0.24944957,\n         0.27857751, -0.11815752,  0.34193225, -0.50272505, -0.06717108],\n       [ 0.61009221,  0.93773575,  0.50819163,  0.34684023,  0.67803081,\n         0.76752317,  0.44797736,  0.99043991,  0.66684383,  0.28661848],\n       [ 0.67741637,  0.03936425,  0.90222193,  0.74297783,  0.09312082,\n         0.24863699,  0.49080556,  0.24127423,  0.60010026, -0.43125147],\n       [ 0.03218154, -0.26417716,  0.94619907,  0.31508274, -0.17567565,\n         0.60747318,  0.64555627,  0.1067521 ,  0.69838349, -0.09207529]]), array([[-0.05445042, -2.38398167,  0.90201861, -1.2862008 ,  0.23084947],\n       [ 1.07576691,  1.43405769, -0.11567486,  0.51555624, -1.52145761],\n       [-1.76726434, -1.36564192, -1.27167033, -0.82139385,  0.62537309]])]\nNeural network model:\n input_dim = 7\n hidden_layers = [10, 5]\n output_dim = 3\n eta = 0.1\n n_epochs = 200\n n_folds = 4\n seed_crossval = 6\nnew weights of the aggreagated model are: [array([[ 1.81465269, -1.88872864,  1.95239993,  0.34201399,  1.95533217,\n        -0.85065373,  1.31767916],\n       [ 1.81743947,  1.78561708, -0.56105011, -1.55249437,  1.99407676,\n        -1.02395852,  1.33814346],\n       [ 1.70295992, -1.34439308,  1.5626738 ,  2.30849625, -0.86011633,\n         1.99763252,  2.04268175],\n       [ 1.00309902,  0.88104633,  1.23366575,  2.48710886, -1.35666026,\n        -0.91392581,  2.02258213],\n       [ 1.83594678, -0.71997565,  1.93830869, -2.13648312,  1.7013274 ,\n        -1.18303994,  1.48188753],\n       [ 2.09008303,  1.60394238,  0.09742937,  0.95631881, -1.56737448,\n         1.69717456,  0.15780355],\n       [-1.77906816,  1.65057056, -1.29366549,  2.42773658, -1.08127185,\n         1.25948626,  1.52432456],\n       [-2.1285142 ,  1.95925839, -0.12475722,  1.61459196,  1.67264946,\n        -0.80595458, -2.3638123 ],\n       [-1.93254296, -1.90684638,  1.4389921 ,  1.85852403,  1.67635183,\n         1.22327214, -1.06351161],\n       [-1.59702097,  1.90836695, -1.63920032, -2.54227799, -2.19220355,\n        -0.93320307, -2.15701531]]), array([[ 0.8529648 ,  0.58828095,  0.71331995,  0.71057454,  0.64400159,\n         0.50785618,  0.28724581, -0.58872777, -0.18242864, -0.37220648],\n       [ 0.11026065,  0.81088462, -0.19287093, -0.24530988,  0.24944957,\n         0.27857751, -0.11815752,  0.34193225, -0.50272505, -0.06717108],\n       [ 0.61009221,  0.93773575,  0.50819163,  0.34684023,  0.67803081,\n         0.76752317,  0.44797736,  0.99043991,  0.66684383,  0.28661848],\n       [ 0.67741637,  0.03936425,  0.90222193,  0.74297783,  0.09312082,\n         0.24863699,  0.49080556,  0.24127423,  0.60010026, -0.43125147],\n       [ 0.03218154, -0.26417716,  0.94619907,  0.31508274, -0.17567565,\n         0.60747318,  0.64555627,  0.1067521 ,  0.69838349, -0.09207529]]), array([[-0.05445042, -2.38398167,  0.90201861, -1.2862008 ,  0.23084947],\n       [ 1.07576691,  1.43405769, -0.11567486,  0.51555624, -1.52145761],\n       [-1.76726434, -1.36564192, -1.27167033, -0.82139385,  0.62537309]])]\n\n\n running predictions on validation sets held . . . . .  \n\n\n\n*****************************FINAL VALIDATION RESULTS ********************\n  \n-> accuracy_genric = 94.29%, acc_split_learn = 37.14% \n\n\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.NN import NN\n",
    "import src.utils as utils\n",
    "import copy\n",
    "import random\n",
    "from box import Box \n",
    "from datetime import datetime\n",
    "# if(__name__ == 'main')\n",
    "# Settings\n",
    "\n",
    "def split_learn(X,y,modelConfig):\n",
    "    datasets,features=X.shape\n",
    "    \n",
    "    splitWeights=list()\n",
    "    splits = np.hsplit(X,features)\n",
    "    # return splits\n",
    "    print(\"splits made = \",len(splits))\n",
    "    for o,oX in enumerate(splits):\n",
    "        N, d = oX.shape\n",
    "\n",
    "        hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "        eta = modelConfig.eta # learning rate\n",
    "        n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "        n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "        seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "        n_classes = modelConfig.n_classes\n",
    "\n",
    "\n",
    "        print(\"Neural network model:\")\n",
    "        print(\" input_dim = {}\".format(d))\n",
    "        print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "        print(\" output_dim = {}\".format(n_classes))\n",
    "        print(\" eta = {}\".format(eta))\n",
    "        print(\" n_epochs = {}\".format(n_epochs))\n",
    "        print(\" n_folds = {}\".format(n_folds))\n",
    "        print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "        # print(\" seed_weights = {}\\n\".format)\n",
    "\n",
    "        # Create cross-validation folds\n",
    "        idx_all = np.arange(0, N)\n",
    "        idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "        \n",
    "        # Train/evaluate the model on each fold\n",
    "        acc_train, acc_valid = list(), list()\n",
    "        print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "        for i, idx_valid in enumerate(idx_folds):\n",
    "            #  seed=seed_weights\n",
    "            # Collect training and test data from folds\n",
    "            idx_train = np.delete(idx_all, idx_valid)\n",
    "            X_train, y_train = oX[idx_train], y[idx_train]\n",
    "            X_valid, y_valid = oX[idx_valid], y[idx_valid]\n",
    "\n",
    "            # Build neural network classifier model and train\n",
    "            model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers)\n",
    "            model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "            # Make predictions for training and test data\n",
    "            ypred_train = model.predict(X_train)\n",
    "            ypred_valid = model.predict(X_valid)\n",
    "\n",
    "            # Compute training/test accuracy score from predicted values\n",
    "            acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "            acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "            # Print cross-validation result\n",
    "            print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "        # Print results\n",
    "        print(o,\" : \")\n",
    "        print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "\n",
    "        splitWeights.append(model.get_weights())\n",
    "        \n",
    "    \n",
    "    return splitWeights\n",
    "\n",
    "def get_aggregate_weights(wt):\n",
    "    new=[]\n",
    "    \n",
    "    # print(\"wth\",new)\n",
    "    rep = copy.deepcopy(wt)\n",
    "    for i,mx in enumerate(rep):\n",
    "        # m2 = wt[i]\n",
    "        if i==0:\n",
    "            print(\"hitting new\")\n",
    "            new = mx\n",
    "            new[0] = new[0].tolist()\n",
    "            # print(new)\n",
    "        else:\n",
    "            for j,lx in enumerate(mx):\n",
    "                if j==0 and i!=0:\n",
    "                    res =[]\n",
    "                    for ni,nx in enumerate(new[j]):\n",
    "                        print(nx,\"  ** \",lx[ni])\n",
    "                        res.append(np.concatenate([nx,lx[ni]]))\n",
    "                    # for wx in res:\n",
    "                    #     new[j].append(wx)\n",
    "                    new [j] =res\n",
    "                else:\n",
    "                    new[j] = np.add(new[j],lx)\n",
    "                    # print(len(new[j]))\n",
    "\n",
    "    for k in range(len(new)):\n",
    "        if not k == 0:\n",
    "            print(k)\n",
    "            new[k] = np.divide(new[k],len(wt))\n",
    "            # print(type(l1))\n",
    "    print( new )\n",
    "    if(len(new)):\n",
    "        new[0] = np.asarray(new[0])\n",
    "    return new\n",
    "\n",
    "\n",
    "def get_aggregate_model(shape,newWeights,modelConfig):\n",
    "    # for oX in enumerate(splits):\n",
    "    # print(\"Reading '{}'...\".format(csv_filename))\n",
    "    # X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "    N, d = shape\n",
    "    #   N, d = X.shape\n",
    "    hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = modelConfig.eta # learning rate\n",
    "    n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "    n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "    seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "    n_classes = modelConfig.n_classes\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "\n",
    "    # list of list of fold indices\n",
    "    model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers,AvgWeights=newWeights)\n",
    "    # Train/evaluate the model on each fold\n",
    "    return model\n",
    "\n",
    "\n",
    "def getGenericNN(X,y,modelConfig):\n",
    "    \n",
    "    N, d = X.shape\n",
    "    hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = modelConfig.eta # learning rate\n",
    "    n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "    n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "    seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "    n_classes = modelConfig.n_classes\n",
    "\n",
    "    print(\" -> X.shape = {}, y.shape = {}, n_classes = {}\\n\".format(X.shape, y.shape, n_classes))\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "\n",
    "    # Create cross-validation folds\n",
    "    idx_all = np.arange(0, N)\n",
    "    idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "    # Train/evaluate the model on each fold\n",
    "    acc_train, acc_valid = list(), list()\n",
    "    print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "    for i, idx_valid in enumerate(idx_folds):\n",
    "\n",
    "        # Collect training and test data from folds\n",
    "        idx_train = np.delete(idx_all, idx_valid)\n",
    "        X_train, y_train = X[idx_train], y[idx_train]\n",
    "        X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        # Build neural network classifier model and train\n",
    "        model = NN(input_dim=d, output_dim=n_classes,\n",
    "                hidden_layers=hidden_layers)\n",
    "\n",
    "        model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "        # Make predictions for training and test data\n",
    "        ypred_train = model.predict(X_train)\n",
    "        ypred_valid = model.predict(X_valid)\n",
    "\n",
    "        # Compute training/test accuracy score from predicted values\n",
    "        acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "        acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "        # Print cross-validation result\n",
    "        print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid = {})\".format(\n",
    "            i+1, n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "    # Print results\n",
    "    print(\"\"\"***************************** GENERIC MODEL TRAINING RESULTS ********************\\n  \n",
    "    -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}% \\n\\n\"\"\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# seed for cross-validation\n",
    "# csv_filename = \"data/tennis.csv\"\n",
    "csv_filename = \"data/seeds_dataset.csv\"\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_c = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "random.seed(datetime.now())\n",
    "config = {\n",
    "    \"n_classes\" : n_c,\n",
    "    \"hidden_layers\" : [10,5], # number of nodes in hidden layers i.e. [layer1, layer2, ...],\n",
    "    \"eta\" : 0.1, # learning rate,\n",
    "    \"n_epochs\" : 200, # number of training epochs,\n",
    "    \"n_folds\" : 4 ,# number of folds for cross-validation,\n",
    "    \"seed\" : random.randrange(0,9)\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "N,d = X.shape\n",
    "fold = utils.crossval_folds(N, 5, seed=config.seed) # list of list of fold indices\n",
    "valid = random.randrange(0,len(fold))\n",
    "validSets = fold[valid]\n",
    "allSets = np.arange(0, N)\n",
    "trainSets = np.delete(allSets, validSets)\n",
    "\n",
    "nX, nY = X[trainSets], y[trainSets]\n",
    "vX, vY = X[validSets], y[validSets]\n",
    "\n",
    "genericModel = getGenericNN(nX, nY, config)\n",
    "newModelWeights = split_learn(nX,nY,config)\n",
    "aggregateWeights = get_aggregate_weights(newModelWeights)\n",
    "newModel = get_aggregate_model(X.shape,aggregateWeights,config)\n",
    "print(\"new weights of the aggreagated model are:\", newModel.get_weights())\n",
    "print ( \"\\n\\n running predictions on validation sets held . . . . .  \\n\\n\")\n",
    "pred_generic = genericModel.predict(vX)\n",
    "pred_newModel = newModel.predict(vX)\n",
    "\n",
    "acc_generic = 100*np.sum(vY==pred_generic)/len(vY)\n",
    "acc_newModel = 100*np.sum(vY==pred_newModel)/len(vY)\n",
    "\n",
    "print(\"\"\"\\n*****************************FINAL VALIDATION RESULTS ********************\\n  \n",
    "-> accuracy_genric = {:.2f}%, acc_split_learn = {:.2f}% \\n\\n\"\"\".format(acc_generic,acc_newModel))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aggregateWeights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1.2325191]   0\n[1.03709112]   1\n"
    }
   ],
   "source": [
    "newx = newModelWeights[0][0]\n",
    "new = newModelWeights[1][0]\n",
    "for ni,nx in enumerate(newx):\n",
    "    print( nx , \" \",ni)\n",
    "    # newx[ni] = np.concatenate([nx,new[ni]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'numpy.ndarray'> [[1.27795065]\n [1.25823811]]\n<class 'list'> [array([1.03709112, 1.25823811]), array([1.03709112, 1.25823811])]\n<class 'numpy.ndarray'> [[1.03709112 1.25823811]\n [1.03709112 1.25823811]]\n"
    }
   ],
   "source": [
    "res = np.concatenate([newx[1],new[1]])\n",
    "# new[1].reshape(res.shape)\n",
    "print ( type( new ), new)\n",
    "new = [res,res]\n",
    "print ( type( new ), new)\n",
    "new = np.asarray(new)\n",
    "print ( type( new ), new)\n",
    "# new\n",
    "# newx[0]\n",
    "# new[0]\n",
    "# new [0]\n",
    "# newx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array([3.60132693, 3.55938977]), array([3.60132693, 3.55938977])]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
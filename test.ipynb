{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitmlvenvvirtualenv7d88894919b14083a2990028bc2685ff",
   "display_name": "Python 3.6.8 64-bit ('ml_venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.NN import NN\n",
    "import src.utils as utils\n",
    "\n",
    "# Settings\n",
    "csv_filename = \"data/seeds_dataset.csv\"\n",
    "hidden_layers = [1,2] # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "eta = 0.1 # learning rate\n",
    "n_epochs = 50 # number of training epochs\n",
    "n_folds = 4 # number of folds for cross-validation\n",
    "seed_crossval = 1 # seed for cross-validation\n",
    "seed_weights = 1 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\n"
    }
   ],
   "source": [
    "\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a48bb6c9b7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m config = {\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mn_classes\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"hidden_layers\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of nodes in hidden layers i.e. [layer1, layer2, ...],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"eta\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# learning rate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# m,n=X.shape\n",
    "# n\n",
    "config = {\n",
    "        n_classes : 25,\n",
    "        \"hidden_layers\" : [1,2], # number of nodes in hidden layers i.e. [layer1, layer2, ...],\n",
    "        \"eta\" : 0.1, # learning rate,\n",
    "        \"n_epochs\" : 50, # number of training epochs,\n",
    "        \"n_folds\" : 4 ,# number of folds for cross-validation,\n",
    "        \"seed_crossval\" : 1 \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'n_clases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-41889a93522f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'n_clases'"
     ]
    }
   ],
   "source": [
    "config.n_clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\n -> X.shape = (144, 7), y.shape = (144,), n_classes = 3\n\nNeural network model:\n input_dim = 7\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 68.52%, acc_valid = 55.56% (n_train = 108, n_valid = 36)\n Fold 2/4: acc_train = 33.33%, acc_valid = 25.00% (n_train = 108, n_valid = 36)\n Fold 3/4: acc_train = 75.00%, acc_valid = 69.44% (n_train = 108, n_valid = 36)\n Fold 4/4: acc_train = 69.44%, acc_valid = 69.44% (n_train = 108, n_valid = 36)\n***************************** GENERIC MODEL TRAINING RESULTS ********************\n  \n    -> acc_train_avg = 61.57%, acc_valid_avg = 54.86% \n\n\nsplits made =  7\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 68.52%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 66.67%, acc_valid = 61.11% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 37.96%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 67.59%, acc_valid = 77.78% (n_train = 108, n_valid 36)\n0  : \n  -> acc_train_avg = 60.19%, acc_valid_avg = 54.86%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 68.52%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 33.33%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 37.96%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 65.74%, acc_valid = 69.44% (n_train = 108, n_valid 36)\n1  : \n  -> acc_train_avg = 51.39%, acc_valid_avg = 43.75%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 54.63%, acc_valid = 47.22% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 52.78%, acc_valid = 61.11% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 53.70%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 58.33%, acc_valid = 44.44% (n_train = 108, n_valid 36)\n2  : \n  -> acc_train_avg = 54.86%, acc_valid_avg = 52.08%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 66.67%, acc_valid = 52.78% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 64.81%, acc_valid = 58.33% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 43.52%, acc_valid = 38.89% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 45.37%, acc_valid = 38.89% (n_train = 108, n_valid 36)\n3  : \n  -> acc_train_avg = 55.09%, acc_valid_avg = 47.22%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 67.59%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 64.81%, acc_valid = 61.11% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 37.96%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 36.11%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n4  : \n  -> acc_train_avg = 51.62%, acc_valid_avg = 42.36%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 51.85%, acc_valid = 58.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 50.00%, acc_valid = 55.56% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 37.96%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 36.11%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n5  : \n  -> acc_train_avg = 43.98%, acc_valid_avg = 41.67%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 33.33%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 50.00%, acc_valid = 36.11% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 37.96%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 41.67%, acc_valid = 36.11% (n_train = 108, n_valid 36)\n6  : \n  -> acc_train_avg = 40.74%, acc_valid_avg = 30.56%\nwth []\nhitting new\n[[ 0.90556243  1.08847322]\n [ 0.03460622 -2.61550934]]\n2\n3\n2\n3\n2\n3\n2\n3\n2\n3\n2\n3\n1\n2\n[[array([ 0.86996283,  2.62530446,  2.34600429,  2.00420878,  0.41822114,\n        1.43146809,  0.95494872,  0.22922223,  0.187624  , -0.11595812,\n        0.78079745,  0.03574866,  0.95555782,  0.68648864])], array([[ 0.51434962,  0.28699806],\n       [-0.0966282 , -0.09652294]]), array([[-0.55532276, -0.44523483],\n       [-0.59276224, -1.48523578],\n       [-0.65534269,  0.13346303]])]\nNeural network model:\n input_dim = 7\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 2\n"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8b964406c8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0mnewModelWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0maggregateWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aggregate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewModelWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mnewModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aggregate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maggregateWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new weights of the aggreagated model are:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m\"\\n\\n running predictions on validation sets held . . . . .  \\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8b964406c8cf>\u001b[0m in \u001b[0;36mget_aggregate_model\u001b[0;34m(shape, newWeights, modelConfig)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# list of list of fold indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     model = NN(input_dim=d, output_dim=n_classes,\n\u001b[0;32m--> 132\u001b[0;31m                         hidden_layers=hidden_layers,AvgWeights=newWeights)\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Train/evaluate the model on each fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, hidden_layers, AvgWeights)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[0;31m# number of output nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layers\u001b[0m \u001b[0;31m# number of hidden nodes @ each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvgWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m_build_network\u001b[0;34m(self, AvgWeights)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAvgWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAvgWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m_layer\u001b[0;34m(input_dim, output_dim, Avgweight)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvgweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvgweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0;31m# weights = [ w for w in rx for rx in  ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAvgweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                     \u001b[0;31m# print(weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.NN import NN\n",
    "import src.utils as utils\n",
    "import copy\n",
    "import random\n",
    "from box import Box \n",
    "from datetime import datetime\n",
    "# if(__name__ == 'main')\n",
    "# Settings\n",
    "\n",
    "def split_learn(X,y,modelConfig):\n",
    "    datasets,features=X.shape\n",
    "    \n",
    "    splitWeights=list()\n",
    "    splits = np.hsplit(X,features)\n",
    "    # return splits\n",
    "    print(\"splits made = \",len(splits))\n",
    "    for o,oX in enumerate(splits):\n",
    "        N, d = oX.shape\n",
    "\n",
    "        hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "        eta = modelConfig.eta # learning rate\n",
    "        n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "        n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "        seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "        n_classes = modelConfig.n_classes\n",
    "\n",
    "\n",
    "        print(\"Neural network model:\")\n",
    "        print(\" input_dim = {}\".format(d))\n",
    "        print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "        print(\" output_dim = {}\".format(n_classes))\n",
    "        print(\" eta = {}\".format(eta))\n",
    "        print(\" n_epochs = {}\".format(n_epochs))\n",
    "        print(\" n_folds = {}\".format(n_folds))\n",
    "        print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "        # print(\" seed_weights = {}\\n\".format)\n",
    "\n",
    "        # Create cross-validation folds\n",
    "        idx_all = np.arange(0, N)\n",
    "        idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "        \n",
    "        # Train/evaluate the model on each fold\n",
    "        acc_train, acc_valid = list(), list()\n",
    "        print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "        for i, idx_valid in enumerate(idx_folds):\n",
    "            #  seed=seed_weights\n",
    "            # Collect training and test data from folds\n",
    "            idx_train = np.delete(idx_all, idx_valid)\n",
    "            X_train, y_train = oX[idx_train], y[idx_train]\n",
    "            X_valid, y_valid = oX[idx_valid], y[idx_valid]\n",
    "\n",
    "            # Build neural network classifier model and train\n",
    "            model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers)\n",
    "            model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "            # Make predictions for training and test data\n",
    "            ypred_train = model.predict(X_train)\n",
    "            ypred_valid = model.predict(X_valid)\n",
    "\n",
    "            # Compute training/test accuracy score from predicted values\n",
    "            acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "            acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "            # Print cross-validation result\n",
    "            print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "        # Print results\n",
    "        print(o,\" : \")\n",
    "        print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "\n",
    "        splitWeights.append(model.get_weights())\n",
    "        \n",
    "    \n",
    "    return splitWeights\n",
    "\n",
    "def get_aggregate_weights(wt):\n",
    "    new=[]\n",
    "    \n",
    "    print(\"wth\",new)\n",
    "    rep = copy.deepcopy(wt)\n",
    "    for i,mx in enumerate(rep):\n",
    "        # m2 = wt[i]\n",
    "        if i==0:\n",
    "            print(\"hitting new\")\n",
    "            new = mx\n",
    "            print(new[1])\n",
    "        else:\n",
    "            for j,lx in enumerate(mx):\n",
    "                if j==0 and i!=0:\n",
    "                    # print(new[j],\"88\",lx)\n",
    "                    #  np.concatenate((array_, add_row), axi/s=0)\n",
    "                    new[j] = [np.append(new[j],lx)]\n",
    "                    # print(len(new[j]),\"*******************\")\n",
    "                else:\n",
    "                    new[j] = np.add(new[j],lx)\n",
    "                    print(len(new[j]))\n",
    "\n",
    "    for k in range(len(new)):\n",
    "        if not k == 0:\n",
    "            print(k)\n",
    "            new[k] = np.divide(new[k],len(wt))\n",
    "            # print(type(l1))\n",
    "    print( new )\n",
    "    return new\n",
    "\n",
    "\n",
    "def get_aggregate_model(shape,newWeights,modelConfig):\n",
    "    # for oX in enumerate(splits):\n",
    "    # print(\"Reading '{}'...\".format(csv_filename))\n",
    "    # X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "    N, d = shape\n",
    "    #   N, d = X.shape\n",
    "    hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = modelConfig.eta # learning rate\n",
    "    n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "    n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "    seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "    n_classes = modelConfig.n_classes\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "\n",
    "    # list of list of fold indices\n",
    "    model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers,AvgWeights=newWeights)\n",
    "    # Train/evaluate the model on each fold\n",
    "    return model\n",
    "\n",
    "\n",
    "def getGenericNN(X,y,modelConfig):\n",
    "    \n",
    "    N, d = X.shape\n",
    "    hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = modelConfig.eta # learning rate\n",
    "    n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "    n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "    seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "    n_classes = modelConfig.n_classes\n",
    "\n",
    "    print(\" -> X.shape = {}, y.shape = {}, n_classes = {}\\n\".format(X.shape, y.shape, n_classes))\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "\n",
    "    # Create cross-validation folds\n",
    "    idx_all = np.arange(0, N)\n",
    "    idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "    # Train/evaluate the model on each fold\n",
    "    acc_train, acc_valid = list(), list()\n",
    "    print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "    for i, idx_valid in enumerate(idx_folds):\n",
    "\n",
    "        # Collect training and test data from folds\n",
    "        idx_train = np.delete(idx_all, idx_valid)\n",
    "        X_train, y_train = X[idx_train], y[idx_train]\n",
    "        X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        # Build neural network classifier model and train\n",
    "        model = NN(input_dim=d, output_dim=n_classes,\n",
    "                hidden_layers=hidden_layers)\n",
    "\n",
    "        model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "        # Make predictions for training and test data\n",
    "        ypred_train = model.predict(X_train)\n",
    "        ypred_valid = model.predict(X_valid)\n",
    "\n",
    "        # Compute training/test accuracy score from predicted values\n",
    "        acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "        acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "        # Print cross-validation result\n",
    "        print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid = {})\".format(\n",
    "            i+1, n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "    # Print results\n",
    "    print(\"\"\"***************************** GENERIC MODEL TRAINING RESULTS ********************\\n  \n",
    "    -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}% \\n\\n\"\"\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# def main():\n",
    "    # seed for cross-validation\n",
    "    # csv_filename = \"data/tennis.csv\"\n",
    "csv_filename = \"data/seeds_dataset.csv\"\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_c = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "random.seed(datetime.now())\n",
    "config = {\n",
    "    \"n_classes\" : n_c,\n",
    "    \"hidden_layers\" : [2,2], # number of nodes in hidden layers i.e. [layer1, layer2, ...],\n",
    "    \"eta\" : 0.1, # learning rate,\n",
    "    \"n_epochs\" : 50, # number of training epochs,\n",
    "    \"n_folds\" : 4 ,# number of folds for cross-validation,\n",
    "    \"seed\" : random.randrange(1,9)\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "N,d = X.shape\n",
    "fold = utils.crossval_folds(N, 5, seed=config.seed) # list of list of fold indices\n",
    "valid = random.randrange(0,len(fold))\n",
    "validSets = fold[valid]\n",
    "allSets = np.arange(0, N)\n",
    "trainSets = np.delete(allSets, validSets)\n",
    "\n",
    "nX, nY = X[trainSets], y[trainSets]\n",
    "vX, vY = X[validSets], y[validSets]\n",
    "\n",
    "genericModel = getGenericNN(nX, nY, config)\n",
    "newModelWeights = split_learn(nX,nY,config)\n",
    "aggregateWeights = get_aggregate_weights(newModelWeights)\n",
    "newModel = get_aggregate_model(X.shape,aggregateWeights,config)\n",
    "print(\"new weights of the aggreagated model are:\", newModel.get_weights())\n",
    "print ( \"\\n\\n running predictions on validation sets held . . . . .  \\n\\n\")\n",
    "pred_generic = genericModel.predict(vX)\n",
    "pred_newModel = newModel.predict(vX)\n",
    "\n",
    "acc_generic = 100*np.sum(vY==pred_generic)/len(vY)\n",
    "acc_newModel = 100*np.sum(vY==pred_newModel)/len(vY)\n",
    "\n",
    "print(\"\"\"\\n*****************************FINAL VALIDATION RESULTS ********************\\n  \n",
    "-> accuracy_genric = {:.2f}%, acc_split_learn = {:.2f}% \\n\\n\"\"\".format(acc_generic,acc_newModel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "14"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aggregateWeights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[-0.15799387955905655, -1.1991673177189213]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt[0][2][0].tolist()\n",
    "# len(new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model.get_weights()[0][])\n",
    "datasets,features=X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "wth []\nhitting new\n[[-1.79562867]\n [ 2.32629109]]\n1 *******************\n2\n3\n1 *******************\n2\n3\n1 *******************\n2\n3\n1 *******************\n2\n3\n1 *******************\n2\n3\n1 *******************\n2\n3\n1\n2\n[[array([2.8611539 , 1.88688159, 1.02089154, 3.72419257, 3.77805387,\n       1.38444096, 3.11121019])], array([[0.12905778],\n       [0.71185533]]), array([[-0.43778527, -0.79024719],\n       [-1.4330232 , -0.35389627],\n       [-0.09639481, -0.61020524]])]\n"
    }
   ],
   "source": [
    "new=[]\n",
    "import copy\n",
    "print(\"wth\",new)\n",
    "rep = copy.deepcopy(wt)\n",
    "for i,mx in enumerate(rep):\n",
    "    # m2 = wt[i]\n",
    "    if i==0:\n",
    "        print(\"hitting new\")\n",
    "        new = mx\n",
    "        print(new[1])\n",
    "    else:\n",
    "        for j,lx in enumerate(mx):\n",
    "            if j==0 and i!=0:\n",
    "                # print(new[j],\"88\",lx)\n",
    "                \n",
    "                new[j] = [np.append(new[j],lx)]\n",
    "                print(len(new[j]),\"*******************\")\n",
    "            else:\n",
    "                new[j] = np.add(new[j],lx)\n",
    "                print(len(new[j]))\n",
    "\n",
    "for k in range(len(new)):\n",
    "    if not k == 0:\n",
    "        print(k)\n",
    "        new[k] = np.divide(new[k],len(wt))\n",
    "        # print(type(l1))\n",
    "print( new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[2.861153897068316, 1.8868815935243572, 1.0208915413338562, 3.7241925687751216, 3.7780538720172014, 1.3844409569515108, 3.111210190876561]\n[0.12905777659894133]\n[0.7118553327841978]\n[-0.4377852655548038, -0.7902471884649697]\n[-1.4330231972115752, -0.3538962702293699]\n[-0.09639481168149029, -0.6102052380595595]\n"
    }
   ],
   "source": [
    "new_nn =  NN(input_dim=features, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers,AvgWeights=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "node :  {'weights': [2.861153897068316, 1.8868815935243572, 1.0208915413338562, 3.7241925687751216, 3.7780538720172014, 1.3844409569515108, 3.111210190876561], 'output': None, 'delta': None}\nnode :  {'weights': [0.12905777659894133], 'output': None, 'delta': None}\nnode :  {'weights': [0.7118553327841978], 'output': None, 'delta': None}\nnode :  {'weights': [-0.4377852655548038, -0.7902471884649697], 'output': None, 'delta': None}\nnode :  {'weights': [-1.4330231972115752, -0.3538962702293699], 'output': None, 'delta': None}\nnode :  {'weights': [-0.09639481168149029, -0.6102052380595595], 'output': None, 'delta': None}\n"
    },
    {
     "data": {
      "text/plain": "[array([[2.8611539 , 1.88688159, 1.02089154, 3.72419257, 3.77805387,\n         1.38444096, 3.11121019]]),\n array([[0.12905778],\n        [0.71185533]]),\n array([[-0.43778527, -0.79024719],\n        [-1.4330232 , -0.35389627],\n        [-0.09639481, -0.61020524]])]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = [[[2.162206105066135,\n",
    "   2.511103755489059,\n",
    "   1.0914315598966,\n",
    "   1.299168673146784,\n",
    "   1.9712199964449098,\n",
    "   -0.6693635968466675,\n",
    "   1.7271965968317686]],\n",
    " [[[0.6449008887629116], [1.2760450946757522]],\n",
    "  [[0.6449008887629116], [1.2760450946757522]]],\n",
    " [[[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]],\n",
    "  [[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]],\n",
    "  [[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp(a, b):\n",
    "    # print(a,b,\"***^^ \\n\")\n",
    "    return sum([float(a_ )* float(b_) for (a_, b_) in zip(a, b)])\n",
    "y=[2.162206105066135,\n",
    "   2.511103755489059,\n",
    "   1.0914315598966,\n",
    "   1.299168673146784,\n",
    "   1.9712199964449098,\n",
    "   -0.6693635968466675,\n",
    "   1.7271965968317686]\n",
    "\n",
    "# new[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp(new[1][0],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\nNeural network model:\n input_dim = 7\n hidden_layers = [1, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\n seed_weights = 1\n\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 68.89%, acc_valid = 59.09% (n_train = 135, n_valid 44)\n Fold 2/4: acc_train = 72.59%, acc_valid = 65.91% (n_train = 135, n_valid 44)\n Fold 3/4: acc_train = 69.63%, acc_valid = 72.73% (n_train = 135, n_valid 44)\n Fold 4/4: acc_train = 71.11%, acc_valid = 72.73% (n_train = 135, n_valid 44)\n  -> acc_train_avg = 70.56%, acc_valid_avg = 67.61%\n"
    }
   ],
   "source": [
    "# for oX in enumerate(splits):\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "N, d = X.shape\n",
    "\n",
    "print(\"Neural network model:\")\n",
    "print(\" input_dim = {}\".format(d))\n",
    "print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "print(\" output_dim = {}\".format(n_classes))\n",
    "print(\" eta = {}\".format(eta))\n",
    "print(\" n_epochs = {}\".format(n_epochs))\n",
    "print(\" n_folds = {}\".format(n_folds))\n",
    "print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "print(\" seed_weights = {}\\n\".format(seed_weights))\n",
    "\n",
    "# Create cross-validation folds\n",
    "idx_all = np.arange(0, N)\n",
    "idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "# Train/evaluate the model on each fold\n",
    "acc_train, acc_valid = list(), list()\n",
    "print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "for i, idx_valid in enumerate(idx_folds):\n",
    "#  seed=seed_weights\n",
    "    # Collect training and test data from folds\n",
    "    idx_train = np.delete(idx_all, idx_valid)\n",
    "    X_train, y_train = X[idx_train], y[idx_train]\n",
    "    X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "    # Build neural network classifier model and train\n",
    "    # model = NN(input_dim=d, output_dim=n_classes,\n",
    "    #             hidden_layers=hidden_layers)\n",
    "    new_nn.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "    # Make predictions for training and test data\n",
    "    ypred_train = new_nn.predict(X_train)\n",
    "    ypred_valid = new_nn.predict(X_valid)\n",
    "\n",
    "    # Compute training/test accuracy score from predicted values\n",
    "    acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "    acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "    # Print cross-validation result\n",
    "    print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "# Print results\n",
    "# print(o,\" : \")\n",
    "print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "node :  {'weights': [2.5872943666380515, 0.8850010414563316, -0.13311296759739202, -0.8379477684719221, 3.491352445580385, 0.8108488588020185, 7.10226748707677], 'output': 5.163950494216946e-05, 'delta': 2.706566185149175e-05}\nnode :  {'weights': [-2.9725823930843545], 'output': 0.4999616243292807, 'delta': -0.07196931755730174}\nnode :  {'weights': [2.8712321295483423], 'output': 0.5000370672513681, 'delta': 0.06262496641362386}\nnode :  {'weights': [2.599976089232433, -2.628929291267122], 'output': 0.4963316098166286, 'delta': 0.1244655031745124}\nnode :  {'weights': [-10.570907995730925, 3.1864178713599958], 'output': 0.02432271284028594, 'delta': 0.000577430305135766}\nnode :  {'weights': [5.2234668320644495, -4.944500874215855], 'output': 0.5347188494053676, 'delta': -0.11617378483881227}\n"
    },
    {
     "data": {
      "text/plain": "[array([[ 2.58729437,  0.88500104, -0.13311297, -0.83794777,  3.49135245,\n          0.81084886,  7.10226749]]),\n array([[-2.97258239],\n        [ 2.87123213]]),\n array([[  2.59997609,  -2.62892929],\n        [-10.570908  ,   3.18641787],\n        [  5.22346683,  -4.94450087]])]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "import copy\n",
    "print(\"wth\",new)\n",
    "rep = copy.deepcopy(wt)\n",
    "for i,mx in enumerate(rep):\n",
    "    # m2 = wt[i]\n",
    "    if i==0:\n",
    "        print(\"hitting new\")\n",
    "        new = mx\n",
    "        print(new[1])\n",
    "    else:\n",
    "        for j,lx in enumerate(mx):\n",
    "            if j==0 and i!=0:\n",
    "                # print(new[j],\"88\",lx)\n",
    "                \n",
    "                new[j] = np.append(new[j],lx)\n",
    "                print(len(new[j]),\"*******************\")\n",
    "            else:\n",
    "                new[j] = np.add(new[j],lx)\n",
    "                print(len(new[j]))\n",
    "\n",
    "for k in range(len(new)):\n",
    "    if not k == 0:\n",
    "        print(k)\n",
    "        new[k] = np.divide(new[k],len(wt))\n",
    "        # print(type(l1))\n",
    "print( new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp=0\n",
    "for fp in range(len(wt)):\n",
    "    print(wt[fp][1])\n",
    "    rp += wt[fp][1][0][0]\n",
    "    print(rp)\n",
    "print(rp/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([ 3.9273942 ,  1.9839786 ,  1.7497002 ,  3.1951442 ,  1.8707918 ,\n",
    "       -0.18531519,  1.9123502 ], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wt[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([ 3.9273942 ,  1.9839786 ,  1.7497002 ,  3.1951442 ,  1.8707918 ,\n",
    "       -0.18531519,  1.9123502 ], dtype=\"float32\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
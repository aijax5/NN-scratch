{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitmlvenvvirtualenv7d88894919b14083a2990028bc2685ff",
   "display_name": "Python 3.6.8 64-bit ('ml_venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.NN import NN\n",
    "import src.utils as utils\n",
    "\n",
    "# Settings\n",
    "csv_filename = \"data/seeds_dataset.csv\"\n",
    "hidden_layers = [1,2] # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "eta = 0.1 # learning rate\n",
    "n_epochs = 50 # number of training epochs\n",
    "n_folds = 4 # number of folds for cross-validation\n",
    "seed_crossval = 1 # seed for cross-validation\n",
    "seed_weights = 1 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\n"
    }
   ],
   "source": [
    "\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m,n=X.shape\n",
    "# n\n",
    "config = {\n",
    "        n_classes : 25,\n",
    "        \"hidden_layers\" : [1,2], # number of nodes in hidden layers i.e. [layer1, layer2, ...],\n",
    "        \"eta\" : 0.1, # learning rate,\n",
    "        \"n_epochs\" : 50, # number of training epochs,\n",
    "        \"n_folds\" : 4 ,# number of folds for cross-validation,\n",
    "        \"seed_crossval\" : 1 \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'n_clases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-41889a93522f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'n_clases'"
     ]
    }
   ],
   "source": [
    "config.n_clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\n -> X.shape = (144, 7), y.shape = (144,), n_classes = 3\n\nNeural network model:\n input_dim = 7\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 74.07%, acc_valid = 75.00% (n_train = 108, n_valid = 36)\n Fold 2/4: acc_train = 68.52%, acc_valid = 55.56% (n_train = 108, n_valid = 36)\n Fold 3/4: acc_train = 63.89%, acc_valid = 72.22% (n_train = 108, n_valid = 36)\n Fold 4/4: acc_train = 60.19%, acc_valid = 38.89% (n_train = 108, n_valid = 36)\n***************************** GENERIC MODEL TRAINING RESULTS ********************\n  \n    -> acc_train_avg = 66.67%, acc_valid_avg = 60.42% \n\n\nsplits made =  7\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 79.63%, acc_valid = 83.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 39.81%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 40.74%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 70.37%, acc_valid = 66.67% (n_train = 108, n_valid 36)\n0  : \n  -> acc_train_avg = 57.64%, acc_valid_avg = 50.69%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 55.56%, acc_valid = 63.89% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 37.96%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 40.74%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 74.07%, acc_valid = 66.67% (n_train = 108, n_valid 36)\n1  : \n  -> acc_train_avg = 52.08%, acc_valid_avg = 45.83%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 37.96%, acc_valid = 33.33% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 43.52%, acc_valid = 33.33% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 40.74%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 38.89%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n2  : \n  -> acc_train_avg = 40.28%, acc_valid_avg = 29.17%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 65.74%, acc_valid = 66.67% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 65.74%, acc_valid = 50.00% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 69.44%, acc_valid = 69.44% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 39.81%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n3  : \n  -> acc_train_avg = 60.19%, acc_valid_avg = 52.78%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 69.44%, acc_valid = 69.44% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 37.96%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 62.96%, acc_valid = 47.22% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 71.30%, acc_valid = 72.22% (n_train = 108, n_valid 36)\n4  : \n  -> acc_train_avg = 60.42%, acc_valid_avg = 54.17%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 47.22%, acc_valid = 44.44% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 37.96%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 40.74%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 38.89%, acc_valid = 25.00% (n_train = 108, n_valid 36)\n5  : \n  -> acc_train_avg = 41.20%, acc_valid_avg = 30.56%\nNeural network model:\n input_dim = 1\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\nCross-validating with 4 folds...\n Fold 1/4: acc_train = 69.44%, acc_valid = 69.44% (n_train = 108, n_valid 36)\n Fold 2/4: acc_train = 37.96%, acc_valid = 27.78% (n_train = 108, n_valid 36)\n Fold 3/4: acc_train = 70.37%, acc_valid = 72.22% (n_train = 108, n_valid 36)\n Fold 4/4: acc_train = 53.70%, acc_valid = 30.56% (n_train = 108, n_valid 36)\n6  : \n  -> acc_train_avg = 57.87%, acc_valid_avg = 50.00%\nwth []\nhitting new\n2\n3\n2\n3\n2\n3\n2\n3\n2\n3\n2\n3\n1\n2\n[[array([ 2.72757163,  2.56373903,  3.01781971,  2.97199231,  1.34135165,\n        1.22838707,  1.57088892,  1.03479298,  2.44809368, -1.93097741,\n        0.43912988, -0.32180735,  1.54038452,  1.38707044])], array([[ 0.3491616 ,  0.79509715],\n       [ 0.49007351, -0.22453818]]), array([[-0.39845195, -0.27616057],\n       [-1.09463841, -0.57975037],\n       [-0.41141234, -0.84675544]])]\nNeural network model:\n input_dim = 7\n hidden_layers = [2, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\n"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-adf2ebb92452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0mnewModelWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0maggregateWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aggregate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewModelWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mnewModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aggregate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maggregateWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new weights of the aggreagated model are:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m\"\\n\\n running predictions on validation sets held . . . . .  \\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-adf2ebb92452>\u001b[0m in \u001b[0;36mget_aggregate_model\u001b[0;34m(shape, newWeights, modelConfig)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# list of list of fold indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     model = NN(input_dim=d, output_dim=n_classes,\n\u001b[0;32m--> 132\u001b[0;31m                         hidden_layers=hidden_layers,AvgWeights=newWeights)\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Train/evaluate the model on each fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, hidden_layers, AvgWeights)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[0;31m# number of output nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layers\u001b[0m \u001b[0;31m# number of hidden nodes @ each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvgWeights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m_build_network\u001b[0;34m(self, AvgWeights)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAvgWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAvgWeights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m_layer\u001b[0;34m(input_dim, output_dim, Avgweight)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvgweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvgweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0;31m# weights = [ w for w in rx for rx in  ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAvgweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                     \u001b[0;31m# print(weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.NN import NN\n",
    "import src.utils as utils\n",
    "import copy\n",
    "import random\n",
    "from box import Box \n",
    "from datetime import datetime\n",
    "# if(__name__ == 'main')\n",
    "# Settings\n",
    "\n",
    "def split_learn(X,y,modelConfig):\n",
    "    datasets,features=X.shape\n",
    "    \n",
    "    splitWeights=list()\n",
    "    splits = np.hsplit(X,features)\n",
    "    # return splits\n",
    "    print(\"splits made = \",len(splits))\n",
    "    for o,oX in enumerate(splits):\n",
    "        N, d = oX.shape\n",
    "\n",
    "        hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "        eta = modelConfig.eta # learning rate\n",
    "        n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "        n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "        seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "        n_classes = modelConfig.n_classes\n",
    "\n",
    "\n",
    "        print(\"Neural network model:\")\n",
    "        print(\" input_dim = {}\".format(d))\n",
    "        print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "        print(\" output_dim = {}\".format(n_classes))\n",
    "        print(\" eta = {}\".format(eta))\n",
    "        print(\" n_epochs = {}\".format(n_epochs))\n",
    "        print(\" n_folds = {}\".format(n_folds))\n",
    "        print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "        # print(\" seed_weights = {}\\n\".format)\n",
    "\n",
    "        # Create cross-validation folds\n",
    "        idx_all = np.arange(0, N)\n",
    "        idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "        \n",
    "        # Train/evaluate the model on each fold\n",
    "        acc_train, acc_valid = list(), list()\n",
    "        print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "        for i, idx_valid in enumerate(idx_folds):\n",
    "            #  seed=seed_weights\n",
    "            # Collect training and test data from folds\n",
    "            idx_train = np.delete(idx_all, idx_valid)\n",
    "            X_train, y_train = oX[idx_train], y[idx_train]\n",
    "            X_valid, y_valid = oX[idx_valid], y[idx_valid]\n",
    "\n",
    "            # Build neural network classifier model and train\n",
    "            model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers)\n",
    "            model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "            # Make predictions for training and test data\n",
    "            ypred_train = model.predict(X_train)\n",
    "            ypred_valid = model.predict(X_valid)\n",
    "\n",
    "            # Compute training/test accuracy score from predicted values\n",
    "            acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "            acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "            # Print cross-validation result\n",
    "            print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "        # Print results\n",
    "        print(o,\" : \")\n",
    "        print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "\n",
    "        splitWeights.append(model.get_weights())\n",
    "        \n",
    "    \n",
    "    return splitWeights\n",
    "\n",
    "def get_aggregate_weights(wt):\n",
    "    new=[]\n",
    "    \n",
    "    print(\"wth\",new)\n",
    "    rep = copy.deepcopy(wt)\n",
    "    for i,mx in enumerate(rep):\n",
    "        # m2 = wt[i]\n",
    "        if i==0:\n",
    "            print(\"hitting new\")\n",
    "            new = mx\n",
    "            # print(new[1])\n",
    "        else:\n",
    "            for j,lx in enumerate(mx):\n",
    "                if j==0 and i!=0:\n",
    "                    # print(new[j],\"88\",lx)\n",
    "                    #  np.concatenate((array_, add_row), axi/s=0)\n",
    "                    new[j] = [np.append(new[j],lx)]\n",
    "                    # print(len(new[j]),\"*******************\")\n",
    "                else:\n",
    "                    new[j] = np.add(new[j],lx)\n",
    "                    print(len(new[j]))\n",
    "\n",
    "    for k in range(len(new)):\n",
    "        if not k == 0:\n",
    "            print(k)\n",
    "            new[k] = np.divide(new[k],len(wt))\n",
    "            # print(type(l1))\n",
    "    print( new )\n",
    "    return new\n",
    "\n",
    "\n",
    "def get_aggregate_model(shape,newWeights,modelConfig):\n",
    "    # for oX in enumerate(splits):\n",
    "    # print(\"Reading '{}'...\".format(csv_filename))\n",
    "    # X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "    N, d = shape\n",
    "    #   N, d = X.shape\n",
    "    hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = modelConfig.eta # learning rate\n",
    "    n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "    n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "    seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "    n_classes = modelConfig.n_classes\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "\n",
    "    # list of list of fold indices\n",
    "    model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers,AvgWeights=newWeights)\n",
    "    # Train/evaluate the model on each fold\n",
    "    return model\n",
    "\n",
    "\n",
    "def getGenericNN(X,y,modelConfig):\n",
    "    \n",
    "    N, d = X.shape\n",
    "    hidden_layers = modelConfig.hidden_layers # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = modelConfig.eta # learning rate\n",
    "    n_epochs = modelConfig.n_epochs# number of training epochs\n",
    "    n_folds = modelConfig.n_folds# number of folds for cross-validation\n",
    "    seed_crossval =modelConfig.seed  # seed for cross-validation\n",
    "    n_classes = modelConfig.n_classes\n",
    "\n",
    "    print(\" -> X.shape = {}, y.shape = {}, n_classes = {}\\n\".format(X.shape, y.shape, n_classes))\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "\n",
    "    # Create cross-validation folds\n",
    "    idx_all = np.arange(0, N)\n",
    "    idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "    # Train/evaluate the model on each fold\n",
    "    acc_train, acc_valid = list(), list()\n",
    "    print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "    for i, idx_valid in enumerate(idx_folds):\n",
    "\n",
    "        # Collect training and test data from folds\n",
    "        idx_train = np.delete(idx_all, idx_valid)\n",
    "        X_train, y_train = X[idx_train], y[idx_train]\n",
    "        X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        # Build neural network classifier model and train\n",
    "        model = NN(input_dim=d, output_dim=n_classes,\n",
    "                hidden_layers=hidden_layers)\n",
    "\n",
    "        model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "        # Make predictions for training and test data\n",
    "        ypred_train = model.predict(X_train)\n",
    "        ypred_valid = model.predict(X_valid)\n",
    "\n",
    "        # Compute training/test accuracy score from predicted values\n",
    "        acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "        acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "        # Print cross-validation result\n",
    "        print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid = {})\".format(\n",
    "            i+1, n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "    # Print results\n",
    "    print(\"\"\"***************************** GENERIC MODEL TRAINING RESULTS ********************\\n  \n",
    "    -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}% \\n\\n\"\"\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# def main():\n",
    "    # seed for cross-validation\n",
    "    # csv_filename = \"data/tennis.csv\"\n",
    "csv_filename = \"data/seeds_dataset.csv\"\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_c = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "random.seed(datetime.now())\n",
    "config = {\n",
    "    \"n_classes\" : n_c,\n",
    "    \"hidden_layers\" : [2,2], # number of nodes in hidden layers i.e. [layer1, layer2, ...],\n",
    "    \"eta\" : 0.1, # learning rate,\n",
    "    \"n_epochs\" : 50, # number of training epochs,\n",
    "    \"n_folds\" : 4 ,# number of folds for cross-validation,\n",
    "    \"seed\" : random.randrange(1,9)\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "N,d = X.shape\n",
    "fold = utils.crossval_folds(N, 5, seed=config.seed) # list of list of fold indices\n",
    "valid = random.randrange(0,len(fold))\n",
    "validSets = fold[valid]\n",
    "allSets = np.arange(0, N)\n",
    "trainSets = np.delete(allSets, validSets)\n",
    "\n",
    "nX, nY = X[trainSets], y[trainSets]\n",
    "vX, vY = X[validSets], y[validSets]\n",
    "\n",
    "genericModel = getGenericNN(nX, nY, config)\n",
    "newModelWeights = split_learn(nX,nY,config)\n",
    "aggregateWeights = get_aggregate_weights(newModelWeights)\n",
    "newModel = get_aggregate_model(X.shape,aggregateWeights,config)\n",
    "print(\"new weights of the aggreagated model are:\", newModel.get_weights())\n",
    "print ( \"\\n\\n running predictions on validation sets held . . . . .  \\n\\n\")\n",
    "pred_generic = genericModel.predict(vX)\n",
    "pred_newModel = newModel.predict(vX)\n",
    "\n",
    "acc_generic = 100*np.sum(vY==pred_generic)/len(vY)\n",
    "acc_newModel = 100*np.sum(vY==pred_newModel)/len(vY)\n",
    "\n",
    "print(\"\"\"\\n*****************************FINAL VALIDATION RESULTS ********************\\n  \n",
    "-> accuracy_genric = {:.2f}%, acc_split_learn = {:.2f}% \\n\\n\"\"\".format(acc_generic,acc_newModel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aggregateWeights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aggregateWeights[0] )#) len(new[1])\n",
    "print(newModelWeights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model.get_weights()[0][])\n",
    "datasets,features=X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "import copy\n",
    "print(\"wth\",new)\n",
    "rep = copy.deepcopy(wt)\n",
    "for i,mx in enumerate(rep):\n",
    "    # m2 = wt[i]\n",
    "    if i==0:\n",
    "        print(\"hitting new\")\n",
    "        new = mx\n",
    "        print(new[1])\n",
    "    else:\n",
    "        for j,lx in enumerate(mx):\n",
    "            if j==0 and i!=0:\n",
    "                # print(new[j],\"88\",lx)\n",
    "                \n",
    "                new[j] = [np.append(new[j],lx)]\n",
    "                print(len(new[j]),\"*******************\")\n",
    "            else:\n",
    "                new[j] = np.add(new[j],lx)\n",
    "                print(len(new[j]))\n",
    "\n",
    "for k in range(len(new)):\n",
    "    if not k == 0:\n",
    "        print(k)\n",
    "        new[k] = np.divide(new[k],len(wt))\n",
    "        # print(type(l1))\n",
    "print( new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn =  NN(input_dim=features, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers,AvgWeights=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = [[[2.162206105066135,\n",
    "   2.511103755489059,\n",
    "   1.0914315598966,\n",
    "   1.299168673146784,\n",
    "   1.9712199964449098,\n",
    "   -0.6693635968466675,\n",
    "   1.7271965968317686]],\n",
    " [[[0.6449008887629116], [1.2760450946757522]],\n",
    "  [[0.6449008887629116], [1.2760450946757522]]],\n",
    " [[[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]],\n",
    "  [[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]],\n",
    "  [[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp(a, b):\n",
    "    # print(a,b,\"***^^ \\n\")\n",
    "    return sum([float(a_ )* float(b_) for (a_, b_) in zip(a, b)])\n",
    "y=[2.162206105066135,\n",
    "   2.511103755489059,\n",
    "   1.0914315598966,\n",
    "   1.299168673146784,\n",
    "   1.9712199964449098,\n",
    "   -0.6693635968466675,\n",
    "   1.7271965968317686]\n",
    "\n",
    "# new[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp(new[1][0],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for oX in enumerate(splits):\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)\n",
    "N, d = X.shape\n",
    "\n",
    "print(\"Neural network model:\")\n",
    "print(\" input_dim = {}\".format(d))\n",
    "print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "print(\" output_dim = {}\".format(n_classes))\n",
    "print(\" eta = {}\".format(eta))\n",
    "print(\" n_epochs = {}\".format(n_epochs))\n",
    "print(\" n_folds = {}\".format(n_folds))\n",
    "print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "print(\" seed_weights = {}\\n\".format(seed_weights))\n",
    "\n",
    "# Create cross-validation folds\n",
    "idx_all = np.arange(0, N)\n",
    "idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "# Train/evaluate the model on each fold\n",
    "acc_train, acc_valid = list(), list()\n",
    "print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "for i, idx_valid in enumerate(idx_folds):\n",
    "#  seed=seed_weights\n",
    "    # Collect training and test data from folds\n",
    "    idx_train = np.delete(idx_all, idx_valid)\n",
    "    X_train, y_train = X[idx_train], y[idx_train]\n",
    "    X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "    # Build neural network classifier model and train\n",
    "    # model = NN(input_dim=d, output_dim=n_classes,\n",
    "    #             hidden_layers=hidden_layers)\n",
    "    new_nn.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "    # Make predictions for training and test data\n",
    "    ypred_train = new_nn.predict(X_train)\n",
    "    ypred_valid = new_nn.predict(X_valid)\n",
    "\n",
    "    # Compute training/test accuracy score from predicted values\n",
    "    acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "    acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "    # Print cross-validation result\n",
    "    print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "# Print results\n",
    "# print(o,\" : \")\n",
    "print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "import copy\n",
    "print(\"wth\",new)\n",
    "rep = copy.deepcopy(wt)\n",
    "for i,mx in enumerate(rep):\n",
    "    # m2 = wt[i]\n",
    "    if i==0:\n",
    "        print(\"hitting new\")\n",
    "        new = mx\n",
    "        print(new[1])\n",
    "    else:\n",
    "        for j,lx in enumerate(mx):\n",
    "            if j==0 and i!=0:\n",
    "                # print(new[j],\"88\",lx)\n",
    "                \n",
    "                new[j] = np.append(new[j],lx)\n",
    "                print(len(new[j]),\"*******************\")\n",
    "            else:\n",
    "                new[j] = np.add(new[j],lx)\n",
    "                print(len(new[j]))\n",
    "\n",
    "for k in range(len(new)):\n",
    "    if not k == 0:\n",
    "        print(k)\n",
    "        new[k] = np.divide(new[k],len(wt))\n",
    "        # print(type(l1))\n",
    "print( new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp=0\n",
    "for fp in range(len(wt)):\n",
    "    print(wt[fp][1])\n",
    "    rp += wt[fp][1][0][0]\n",
    "    print(rp)\n",
    "print(rp/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([ 3.9273942 ,  1.9839786 ,  1.7497002 ,  3.1951442 ,  1.8707918 ,\n",
    "       -0.18531519,  1.9123502 ], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wt[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([ 3.9273942 ,  1.9839786 ,  1.7497002 ,  3.1951442 ,  1.8707918 ,\n",
    "       -0.18531519,  1.9123502 ], dtype=\"float32\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
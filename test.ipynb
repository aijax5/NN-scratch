{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitmlvenvvirtualenv7d88894919b14083a2990028bc2685ff",
   "display_name": "Python 3.6.8 64-bit ('ml_venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.NN import NN\n",
    "import src.utils as utils\n",
    "\n",
    "# Settings\n",
    "csv_filename = \"data/seeds_dataset.csv\"\n",
    "hidden_layers = [1,2] # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "eta = 0.1 # learning rate\n",
    "n_epochs = 50 # number of training epochs\n",
    "n_folds = 4 # number of folds for cross-validation\n",
    "seed_crossval = 1 # seed for cross-validation\n",
    "seed_weights = 1 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading 'data/seeds_dataset.csv'...\n"
    }
   ],
   "source": [
    "\n",
    "print(\"Reading '{}'...\".format(csv_filename))\n",
    "X, y, n_classes = utils.read_csv(csv_filename, target_name=\"y\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n=X.shape\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(X):\n",
    "    datasets,features=X.shape\n",
    "\n",
    "    splitWeights=list()\n",
    "    splits = np.hsplit(X,features)\n",
    "    # return splits\n",
    "\n",
    "    for o,oX in enumerate(splits):\n",
    "        N, d = oX.shape\n",
    "\n",
    "        print(\"Neural network model:\")\n",
    "        print(\" input_dim = {}\".format(d))\n",
    "        print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "        print(\" output_dim = {}\".format(n_classes))\n",
    "        print(\" eta = {}\".format(eta))\n",
    "        print(\" n_epochs = {}\".format(n_epochs))\n",
    "        print(\" n_folds = {}\".format(n_folds))\n",
    "        print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "        print(\" seed_weights = {}\\n\".format(seed_weights))\n",
    "\n",
    "        # Create cross-validation folds\n",
    "        idx_all = np.arange(0, N)\n",
    "        idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "        # Train/evaluate the model on each fold\n",
    "        acc_train, acc_valid = list(), list()\n",
    "        print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "        for i, idx_valid in enumerate(idx_folds):\n",
    "#  seed=seed_weights\n",
    "            # Collect training and test data from folds\n",
    "            idx_train = np.delete(idx_all, idx_valid)\n",
    "            X_train, y_train = oX[idx_train], y[idx_train]\n",
    "            X_valid, y_valid = oX[idx_valid], y[idx_valid]\n",
    "\n",
    "            # Build neural network classifier model and train\n",
    "            model = NN(input_dim=d, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers)\n",
    "            model.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "            # Make predictions for training and test data\n",
    "            ypred_train = model.predict(X_train)\n",
    "            ypred_valid = model.predict(X_valid)\n",
    "\n",
    "            # Compute training/test accuracy score from predicted values\n",
    "            acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "            acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "            # Print cross-validation result\n",
    "            print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "        # Print results\n",
    "        print(o,\" : \")\n",
    "        print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "\n",
    "        splitWeights.append(model.get_weights())\n",
    "        \n",
    "    \n",
    "    return splitWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "55393286035514] [0.2056161259223287] ***^^ \n\n[1.606867282207214] [0.2056161259223287] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5020846235625482, 0.5818561707497238] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5020846235625482, 0.5818561707497238] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5020846235625482, 0.5818561707497238] ***^^ \n\n[1.7271965968317686] [-0.74377857] ***^^ \n\n[0.04055393286035514] [0.2167594216762383] ***^^ \n\n[1.606867282207214] [0.2167594216762383] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5021975976073391, 0.5862061515108987] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5021975976073391, 0.5862061515108987] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5021975976073391, 0.5862061515108987] ***^^ \n\n[1.7271965968317686] [-1.47771663] ***^^ \n\n[0.04055393286035514] [0.07227164243648732] ***^^ \n\n[1.606867282207214] [0.07227164243648732] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5007327243092504, 0.5290001494507203] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5007327243092504, 0.5290001494507203] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5007327243092504, 0.5290001494507203] ***^^ \n\n[1.7271965968317686] [0.03093383] ***^^ \n\n[0.04055393286035514] [0.5133540233453022] ***^^ \n\n[1.606867282207214] [0.5133540233453022] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5052044431785468, 0.6952737423708683] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5052044431785468, 0.6952737423708683] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5052044431785468, 0.6952737423708683] ***^^ \n\n[1.7271965968317686] [1.2745511] ***^^ \n\n[0.04055393286035514] [0.9003751894307042] ***^^ \n\n[1.606867282207214] [0.9003751894307042] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5091274246696745, 0.8095029076165637] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5091274246696745, 0.8095029076165637] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5091274246696745, 0.8095029076165637] ***^^ \n\n[1.7271965968317686] [-0.06488586] ***^^ \n\n[0.04055393286035514] [0.47201162669287494] ***^^ \n\n[1.606867282207214] [0.47201162669287494] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5047853358378467, 0.6810192984181032] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5047853358378467, 0.6810192984181032] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5047853358378467, 0.6810192984181032] ***^^ \n\n[1.7271965968317686] [-0.84775313] ***^^ \n\n[0.04055393286035514] [0.18782024574252235] ***^^ \n\n[1.606867282207214] [0.18782024574252235] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5019042032026724, 0.5748830222747662] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5019042032026724, 0.5748830222747662] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5019042032026724, 0.5748830222747662] ***^^ \n\n[1.7271965968317686] [-1.26976752] ***^^ \n\n[0.04055393286035514] [0.1003683816799583] ***^^ \n\n[1.606867282207214] [0.1003683816799583] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5010175817480803, 0.5402324983019403] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5010175817480803, 0.5402324983019403] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5010175817480803, 0.5402324983019403] ***^^ \n\n[1.7271965968317686] [-0.96192127] ***^^ \n\n[0.04055393286035514] [0.15957051204524553] ***^^ \n\n[1.606867282207214] [0.15957051204524553] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5016177973123459, 0.5637532507072365] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5016177973123459, 0.5637532507072365] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5016177973123459, 0.5637532507072365] ***^^ \n\n[1.7271965968317686] [-0.41962259] ***^^ \n\n[0.04055393286035514] [0.3263433047699503] ***^^ \n\n[1.606867282207214] [0.3263433047699503] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5033085778258758, 0.6281738093962184] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5033085778258758, 0.6281738093962184] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5033085778258758, 0.6281738093962184] ***^^ \n\n[1.7271965968317686] [-0.60310711] ***^^ \n\n[0.04055393286035514] [0.2608250900343178] ***^^ \n\n[1.606867282207214] [0.2608250900343178] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5026443461426181, 0.60327057306597] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5026443461426181, 0.60327057306597] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5026443461426181, 0.60327057306597] ***^^ \n\n[1.7271965968317686] [-0.40127414] ***^^ \n\n[0.04055393286035514] [0.33334841041649693] ***^^ \n\n[1.606867282207214] [0.33334841041649693] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5033795957948797, 0.630799138723985] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5033795957948797, 0.630799138723985] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5033795957948797, 0.630799138723985] ***^^ \n\n[1.7271965968317686] [-0.87017902] ***^^ \n\n[0.04055393286035514] [0.18198294163111636] ***^^ \n\n[1.606867282207214] [0.18198294163111636] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5018450226248816, 0.5725890813813156] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5018450226248816, 0.5725890813813156] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5018450226248816, 0.5725890813813156] ***^^ \n\n[1.7271965968317686] [1.10737632] ***^^ \n\n[0.04055393286035514] [0.8713173096035466] ***^^ \n\n[1.606867282207214] [0.8713173096035466] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5088329168824828, 0.8021983724758052] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5088329168824828, 0.8021983724758052] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5088329168824828, 0.8021983724758052] ***^^ \n\n[1.7271965968317686] [1.08902787] ***^^ \n\n[0.04055393286035514] [0.8677219545796225] ***^^ \n\n[1.606867282207214] [0.8677219545796225] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5087964767648829, 0.8012800586891805] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5087964767648829, 0.8012800586891805] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5087964767648829, 0.8012800586891805] ***^^ \n\n[1.7271965968317686] [-0.87017902] ***^^ \n\n[0.04055393286035514] [0.18198294163111636] ***^^ \n\n[1.606867282207214] [0.18198294163111636] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5018450226248816, 0.5725890813813156] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5018450226248816, 0.5725890813813156] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5018450226248816, 0.5725890813813156] ***^^ \n\n[1.7271965968317686] [-0.77843676] ***^^ \n\n[0.04055393286035514] [0.20676882458426632] ***^^ \n\n[1.606867282207214] [0.20676882458426632] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5020963099742994, 0.5823067499793922] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5020963099742994, 0.5823067499793922] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5020963099742994, 0.5823067499793922] ***^^ \n\n[1.7271965968317686] [-0.7356237] ***^^ \n\n[0.04055393286035514] [0.21916024772781917] ***^^ \n\n[1.606867282207214] [0.21916024772781917] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5022219378665302, 0.5871416221438276] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5022219378665302, 0.5871416221438276] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5022219378665302, 0.5871416221438276] ***^^ \n\n[1.7271965968317686] [-0.42166131] ***^^ \n\n[0.04055393286035514] [0.3255696519971259] ***^^ \n\n[1.606867282207214] [0.3255696519971259] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5033007345028594, 0.6278833970689134] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5033007345028594, 0.6278833970689134] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5033007345028594, 0.6278833970689134] ***^^ \n\n[1.7271965968317686] [-0.96192127] ***^^ \n\n[0.04055393286035514] [0.15957051204524553] ***^^ \n\n[1.606867282207214] [0.15957051204524553] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5016177973123459, 0.5637532507072365] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5016177973123459, 0.5637532507072365] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5016177973123459, 0.5637532507072365] ***^^ \n\n[1.7271965968317686] [-0.56641021] ***^^ \n\n[0.04055393286035514] [0.2732288771686506] ***^^ \n\n[1.606867282207214] [0.2732288771686506] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5027700980429434, 0.6080308643426481] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5027700980429434, 0.6080308643426481] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5027700980429434, 0.6080308643426481] ***^^ \n\n[1.7271965968317686] [-0.40739029] ***^^ \n\n[0.04055393286035514] [0.3310049947852837] ***^^ \n\n[1.606867282207214] [0.3310049947852837] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.503355838192679, 0.629921740864051] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.503355838192679, 0.629921740864051] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.503355838192679, 0.629921740864051] ***^^ \n\n[1.7271965968317686] [1.28882212] ***^^ \n\n[0.04055393286035514] [0.9025644680110242] ***^^ \n\n[1.606867282207214] [0.9025644680110242] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5091496132192462, 0.8100448021287875] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5091496132192462, 0.8100448021287875] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5091496132192462, 0.8100448021287875] ***^^ \n\n[1.7271965968317686] [0.74040729] ***^^ \n\n[0.04055393286035514] [0.7822503709425732] ***^^ \n\n[1.606867282207214] [0.7822503709425732] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5079301672103498, 0.7785045050367712] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5079301672103498, 0.7785045050367712] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5079301672103498, 0.7785045050367712] ***^^ \n\n[1.7271965968317686] [-1.31869672] ***^^ \n\n[0.04055393286035514] [0.09299109879978816] ***^^ \n\n[1.606867282207214] [0.09299109879978816] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5009427875770049, 0.5372867372896419] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5009427875770049, 0.5372867372896419] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5009427875770049, 0.5372867372896419] ***^^ \n\n[1.7271965968317686] [-0.86610158] ***^^ \n\n[0.04055393286035514] [0.1830336777884401] ***^^ \n\n[1.606867282207214] [0.1830336777884401] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5018556753498828, 0.5730022325954983] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5018556753498828, 0.5730022325954983] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5018556753498828, 0.5730022325954983] ***^^ \n\n[1.7271965968317686] [-0.77843676] ***^^ \n\n[0.04055393286035514] [0.20676882458426632] ***^^ \n\n[1.606867282207214] [0.20676882458426632] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5020963099742994, 0.5823067499793922] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5020963099742994, 0.5823067499793922] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5020963099742994, 0.5823067499793922] ***^^ \n\n[1.7271965968317686] [0.83418826] ***^^ \n\n[0.04055393286035514] [0.8085796081902715] ***^^ \n\n[1.606867282207214] [0.8085796081902715] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5081970363067484, 0.7857138030603715] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5081970363067484, 0.7857138030603715] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5081970363067484, 0.7857138030603715] ***^^ \n\n[1.7271965968317686] [1.09514402] ***^^ \n\n[0.04055393286035514] [0.8689297698170111] ***^^ \n\n[1.606867282207214] [0.8689297698170111] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5088087183840143, 0.801588912022444] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5088087183840143, 0.801588912022444] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5088087183840143, 0.801588912022444] ***^^ \n\n[1.7271965968317686] [1.7230688] ***^^ \n\n[0.04055393286035514] [0.9514816613602404] ***^^ \n\n[1.606867282207214] [0.9514816613602404] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5096453841283263, 0.8218460097331343] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5096453841283263, 0.8218460097331343] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5096453841283263, 0.8218460097331343] ***^^ \n\n[1.7271965968317686] [-1.85284053] ***^^ \n\n[0.04055393286035514] [0.03915744989155742] ***^^ \n\n[1.606867282207214] [0.03915744989155742] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5003969970650454, 0.5157250186283016] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5003969970650454, 0.5157250186283016] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5003969970650454, 0.5157250186283016] ***^^ \n\n[1.7271965968317686] [-0.51340357] ***^^ \n\n[0.04055393286035514] [0.29178119619927434] ***^^ \n\n[1.606867282207214] [0.29178119619927434] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5029581842439019, 0.6151123966883039] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5029581842439019, 0.6151123966883039] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5029581842439019, 0.6151123966883039] ***^^ \n\n[1.7271965968317686] [-0.8681403] ***^^ \n\n[0.04055393286035514] [0.18250772236233476] ***^^ \n\n[1.606867282207214] [0.18250772236233476] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5018503430328616, 0.5727954387372509] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5018503430328616, 0.5727954387372509] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5018503430328616, 0.5727954387372509] ***^^ \n\n[1.7271965968317686] [-0.94765026] ***^^ \n\n[0.04055393286035514] [0.16290391715222807] ***^^ \n\n[1.606867282207214] [0.16290391715222807] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5016515926228203, 0.5650701120538301] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5016515926228203, 0.5650701120538301] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5016515926228203, 0.5650701120538301] ***^^ \n\n[1.7271965968317686] [0.12879223] ***^^ \n\n[0.04055393286035514] [0.5553841805723766] ***^^ \n\n[1.606867282207214] [0.5553841805723766] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5056305151711624, 0.7093911101691077] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5056305151711624, 0.7093911101691077] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5056305151711624, 0.7093911101691077] ***^^ \n\n[1.7271965968317686] [-0.18313144] ***^^ \n\n[0.04055393286035514] [0.4215767538798904] ***^^ \n\n[1.606867282207214] [0.4215767538798904] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5042740447372727, 0.663162154382352] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5042740447372727, 0.663162154382352] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5042740447372727, 0.663162154382352] ***^^ \n\n[1.7271965968317686] [0.6568199] ***^^ \n\n[0.04055393286035514] [0.7566605007413095] ***^^ \n\n[1.606867282207214] [0.7566605007413095] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5076707878923127, 0.7713329316055801] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5076707878923127, 0.7713329316055801] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5076707878923127, 0.7713329316055801] ***^^ \n\n[1.7271965968317686] [-0.6744622] ***^^ \n\n[0.04055393286035514] [0.23777284759197592] ***^^ \n\n[1.606867282207214] [0.23777284759197592] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5024106373458823, 0.5943721221982875] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5024106373458823, 0.5943721221982875] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5024106373458823, 0.5943721221982875] ***^^ \n\n[1.7271965968317686] [-0.13827967] ***^^ \n\n[0.04055393286035514] [0.44057317643622257] ***^^ \n\n[1.606867282207214] [0.44057317643622257] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5044666249320074, 0.6699463953481574] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5044666249320074, 0.6699463953481574] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5044666249320074, 0.6699463953481574] ***^^ \n\n[1.7271965968317686] [-0.42573875] ***^^ \n\n[0.04055393286035514] [0.3240251988689411] ***^^ \n\n[1.606867282207214] [0.3240251988689411] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5032850767698949, 0.6273033671182632] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5032850767698949, 0.6273033671182632] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5032850767698949, 0.6273033671182632] ***^^ \n\n[1.7271965968317686] [1.38871924] ***^^ \n\n[0.04055393286035514] [0.9167198082238823] ***^^ \n\n[1.606867282207214] [0.9167198082238823] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5092930780836937, 0.8135200834425308] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5092930780836937, 0.8135200834425308] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5092930780836937, 0.8135200834425308] ***^^ \n\n[1.7271965968317686] [-0.50932614] ***^^ \n\n[0.04055393286035514] [0.29323863036595554] ***^^ \n\n[1.606867282207214] [0.29323863036595554] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5029729598959337, 0.6156666905853163] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5029729598959337, 0.6156666905853163] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5029729598959337, 0.6156666905853163] ***^^ \n\n[1.7271965968317686] [-0.75804959] ***^^ \n\n[0.04055393286035514] [0.21260389059200152] ***^^ \n\n[1.606867282207214] [0.21260389059200152] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5021554676235603, 0.5845855009044538] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5021554676235603, 0.5845855009044538] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5021554676235603, 0.5845855009044538] ***^^ \n\n[1.7271965968317686] [2.07984425] ***^^ \n\n[0.04055393286035514] [0.9732029258056691] ***^^ \n\n[1.606867282207214] [0.9732029258056691] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5098655209671565, 0.8268990887745981] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5098655209671565, 0.8268990887745981] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5098655209671565, 0.8268990887745981] ***^^ \n\n[1.7271965968317686] [-0.3360352] ***^^ \n\n[0.04055393286035514] [0.35884082083471036] ***^^ \n\n[1.606867282207214] [0.35884082083471036] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5036380374361134, 0.6402868969230797] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5036380374361134, 0.6402868969230797] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5036380374361134, 0.6402868969230797] ***^^ \n\n[1.7271965968317686] [-0.24021551] ***^^ \n\n[0.04055393286035514] [0.39773791687762966] ***^^ \n\n[1.606867282207214] [0.39773791687762966] ***^^ \n\n[-0.7356684651611319, -0.9133720838036807] [0.5040323717689179, 0.6545527097108736] ***^^ \n\n[-1.2575266409445582, 0.5955795230644011] [0.5040323717689179, 0.6545527097108736] ***^^ \n\n[-0.5903369500430965, -0.7767408983753207] [0.5040323717689179, 0.6545527097108736] ***^^ \n\n Fold 4/4: acc_train = 39.26%, acc_valid = 25.00% (n_train = 135, n_valid 44)\n6  : \n  -> acc_train_avg = 50.56%, acc_valid_avg = 40.34%\nnode :  {'weights': [1.7271965968317686], 'output': 0.39773791687762966, 'delta': 0.008187886096125321}\nnode :  {'weights': [0.04055393286035514], 'output': 0.5040323717689179, 'delta': -0.021886994403881893}\nnode :  {'weights': [1.606867282207214], 'output': 0.6545527097108736, 'delta': 0.030539269104670964}\nnode :  {'weights': [-0.7356684651611319, -0.9133720838036807], 'output': 0.275149489354238, 'delta': 0.05930700353826569}\nnode :  {'weights': [-1.2575266409445582, 0.5955795230644011], 'output': 0.4393018491948584, 'delta': 0.10582905125001739}\nnode :  {'weights': [-0.5903369500430965, -0.7767408983753207], 'output': 0.30875061296236955, 'delta': -0.1479250366531205}\n"
    }
   ],
   "source": [
    "wt = get_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-64ffa6b64d4b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-64ffa6b64d4b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (wt [1][1])len(new[1])\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(wt [1][1])len(new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model.get_weights()[0][])\n",
    "datasets,features=X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "wth []\nhitting new\n[[2.1209449227289645], [-0.19948450982853366]]\n2 *******************\n2\n3\n3 *******************\n2\n3\n4 *******************\n2\n3\n5 *******************\n2\n3\n6 *******************\n2\n3\n7 *******************\n2\n3\n1\n2\n[array([ 2.16220611,  2.51110376,  1.09143156,  1.29916867,  1.97122   ,\n       -0.6693636 ,  1.7271966 ]), array([[0.64490089],\n       [1.27604509]]), array([[-0.71725832, -0.86275405],\n       [-0.63578179,  0.01427466],\n       [-0.50197709, -0.78656383]])]\n"
    }
   ],
   "source": [
    "new=[]\n",
    "import copy\n",
    "print(\"wth\",new)\n",
    "rep = copy.deepcopy(wt)\n",
    "for i,mx in enumerate(rep):\n",
    "    # m2 = wt[i]\n",
    "    if i==0:\n",
    "        print(\"hitting new\")\n",
    "        new = mx\n",
    "        print(new[1])\n",
    "    else:\n",
    "        for j,lx in enumerate(mx):\n",
    "            if j==0 and i!=0:\n",
    "                # print(new[j],\"88\",lx)\n",
    "                \n",
    "                new[j] = np.append(new[j],lx)\n",
    "                print(len(new[j]),\"*******************\")\n",
    "            else:\n",
    "                new[j] = np.add(new[j],lx)\n",
    "                print(len(new[j]))\n",
    "\n",
    "for k in range(len(new)):\n",
    "    if not k == 0:\n",
    "        print(k)\n",
    "        new[k] = np.divide(new[k],len(wt))\n",
    "        # print(type(l1))\n",
    "print( new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nn =  NN(input_dim=features, output_dim=n_classes,\n",
    "                        hidden_layers=hidden_layers,AvgWeights=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "node :  {'weights': [2.162206105066135, 2.511103755489059, 1.0914315598966, 1.299168673146784, 1.9712199964449098, -0.6693635968466675, 1.7271965968317686], 'output': None, 'delta': None}\nnode :  {'weights': [[0.6449008887629116], [1.2760450946757522]], 'output': None, 'delta': None}\nnode :  {'weights': [[0.6449008887629116], [1.2760450946757522]], 'output': None, 'delta': None}\nnode :  {'weights': [[-0.7172583226205111, -0.862754050663147], [-0.635781787018038, 0.01427466090778091], [-0.5019770862022626, -0.7865638296664071]], 'output': None, 'delta': None}\nnode :  {'weights': [[-0.7172583226205111, -0.862754050663147], [-0.635781787018038, 0.01427466090778091], [-0.5019770862022626, -0.7865638296664071]], 'output': None, 'delta': None}\nnode :  {'weights': [[-0.7172583226205111, -0.862754050663147], [-0.635781787018038, 0.01427466090778091], [-0.5019770862022626, -0.7865638296664071]], 'output': None, 'delta': None}\n"
    },
    {
     "data": {
      "text/plain": "[[[2.162206105066135,\n   2.511103755489059,\n   1.0914315598966,\n   1.299168673146784,\n   1.9712199964449098,\n   -0.6693635968466675,\n   1.7271965968317686]],\n [[[0.6449008887629116], [1.2760450946757522]],\n  [[0.6449008887629116], [1.2760450946757522]]],\n [[[-0.7172583226205111, -0.862754050663147],\n   [-0.635781787018038, 0.01427466090778091],\n   [-0.5019770862022626, -0.7865638296664071]],\n  [[-0.7172583226205111, -0.862754050663147],\n   [-0.635781787018038, 0.01427466090778091],\n   [-0.5019770862022626, -0.7865638296664071]],\n  [[-0.7172583226205111, -0.862754050663147],\n   [-0.635781787018038, 0.01427466090778091],\n   [-0.5019770862022626, -0.7865638296664071]]]]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = [[[2.162206105066135,\n",
    "   2.511103755489059,\n",
    "   1.0914315598966,\n",
    "   1.299168673146784,\n",
    "   1.9712199964449098,\n",
    "   -0.6693635968466675,\n",
    "   1.7271965968317686]],\n",
    " [[[0.6449008887629116], [1.2760450946757522]],\n",
    "  [[0.6449008887629116], [1.2760450946757522]]],\n",
    " [[[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]],\n",
    "  [[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]],\n",
    "  [[-0.7172583226205111, -0.862754050663147],\n",
    "   [-0.635781787018038, 0.01427466090778091],\n",
    "   [-0.5019770862022626, -0.7865638296664071]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.64490089],\n       [1.27604509]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Neural network model:\n input_dim = 7\n hidden_layers = [1, 2]\n output_dim = 3\n eta = 0.1\n n_epochs = 50\n n_folds = 4\n seed_crossval = 1\n seed_weights = 1\n\nCross-validating with 4 folds...\n[2.162206105066135, 2.511103755489059, 1.0914315598966, 1.299168673146784, 1.9712199964449098, -0.6693635968466675, 1.7271965968317686] [ 0.08766787  0.16281232 -0.05732034  0.25848062  0.07986931 -0.92262221\n -0.42370003] ***^^ \n\n[[0.6449008887629116], [1.2760450946757522]] [0.7139895040470035] ***^^ \n\n"
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d8e22ca35856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# model = NN(input_dim=d, output_dim=n_classes,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#             hidden_layers=hidden_layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mnew_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Make predictions for training and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, eta, n_epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward pass (update node[\"output\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0myhot_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# one-hot target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhot_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backward pass error (update node[\"delta\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dotprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mx_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_out\u001b[0m \u001b[0;31m# set output as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m_dotprod\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dotprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"***^^ \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# Sigmoid (activation function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/vsplit-nn/NN-scratch/src/NN.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dotprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"***^^ \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# Sigmoid (activation function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "# for oX in enumerate(splits):\n",
    "N, d = X.shape\n",
    "\n",
    "print(\"Neural network model:\")\n",
    "print(\" input_dim = {}\".format(d))\n",
    "print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "print(\" output_dim = {}\".format(n_classes))\n",
    "print(\" eta = {}\".format(eta))\n",
    "print(\" n_epochs = {}\".format(n_epochs))\n",
    "print(\" n_folds = {}\".format(n_folds))\n",
    "print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "print(\" seed_weights = {}\\n\".format(seed_weights))\n",
    "\n",
    "# Create cross-validation folds\n",
    "idx_all = np.arange(0, N)\n",
    "idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "# Train/evaluate the model on each fold\n",
    "acc_train, acc_valid = list(), list()\n",
    "print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "for i, idx_valid in enumerate(idx_folds):\n",
    "#  seed=seed_weights\n",
    "    # Collect training and test data from folds\n",
    "    idx_train = np.delete(idx_all, idx_valid)\n",
    "    X_train, y_train = X[idx_train], y[idx_train]\n",
    "    X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "    # Build neural network classifier model and train\n",
    "    # model = NN(input_dim=d, output_dim=n_classes,\n",
    "    #             hidden_layers=hidden_layers)\n",
    "    new_nn.train(X_train, y_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "    # Make predictions for training and test data\n",
    "    ypred_train = new_nn.predict(X_train)\n",
    "    ypred_valid = new_nn.predict(X_valid)\n",
    "\n",
    "    # Compute training/test accuracy score from predicted values\n",
    "    acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "    acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "    # Print cross-validation result\n",
    "    print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid {})\".format(i+1,n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "# Print results\n",
    "print(o,\" : \")\n",
    "print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "import copy\n",
    "print(\"wth\",new)\n",
    "rep = copy.deepcopy(wt)\n",
    "for i,mx in enumerate(rep):\n",
    "    # m2 = wt[i]\n",
    "    if i==0:\n",
    "        print(\"hitting new\")\n",
    "        new = mx\n",
    "        print(new[1])\n",
    "    else:\n",
    "        for j,lx in enumerate(mx):\n",
    "            if j==0 and i!=0:\n",
    "                # print(new[j],\"88\",lx)\n",
    "                \n",
    "                new[j] = np.append(new[j],lx)\n",
    "                print(len(new[j]),\"*******************\")\n",
    "            else:\n",
    "                new[j] = np.add(new[j],lx)\n",
    "                print(len(new[j]))\n",
    "\n",
    "for k in range(len(new)):\n",
    "    if not k == 0:\n",
    "        print(k)\n",
    "        new[k] = np.divide(new[k],len(wt))\n",
    "        # print(type(l1))\n",
    "print( new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp=0\n",
    "for fp in range(len(wt)):\n",
    "    print(wt[fp][1])\n",
    "    rp += wt[fp][1][0][0]\n",
    "    print(rp)\n",
    "print(rp/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([ 3.9273942 ,  1.9839786 ,  1.7497002 ,  3.1951442 ,  1.8707918 ,\n",
    "       -0.18531519,  1.9123502 ], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[1.185179945930981], [2.1572901168471024]]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for()"
   ]
  }
 ]
}